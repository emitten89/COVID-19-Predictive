{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Machine Learning Algorithms Applied**\n\n1. K-Mean Clustering\n2. Regression Model\n3. Prophet\n4. Arima \n5. LSTM "},{"metadata":{},"cell_type":"markdown","source":"**Libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport plotly.express as px\nfrom datetime import date, timedelta\nfrom sklearn.cluster import KMeans\nfrom fbprophet import Prophet\nfrom fbprophet.plot import plot_plotly, add_changepoints_to_plot\nimport plotly.offline as py\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport statsmodels.api as sm\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dense\nfrom keras.layers import Dropout\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reading Data**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = '/kaggle/input/coronavirusdataset/'\npatient_data_path = path + 'patient.csv'\nroute_data_path = path + 'route.csv'\ntime_data_path = path + 'time.csv'\n\ndf_patient = pd.read_csv(patient_data_path)\ndf_route = pd.read_csv(route_data_path)\ndf_time = pd.read_csv(time_data_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Looking into patient data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_patient.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.  **id** the ID of the patient (n-th confirmed patient)\n2.  **sex** the sex of the patient\n3.  **birth_year** the birth year of the patient\n4.  **country** the country of the patient\n5.  **region** the region of the patient\n6.  **group** the collective infection\n7.  **infection_reason** the reason of infection\n8.  **infection_order** the order of infection\n9.  **infected_by** the ID of who has infected the patient\n10. **contact_number** the number of contacts with people\n11. **confirmed_date** the date of confirmation\n12. **released_date** the date of discharge\n13. **deceased_date** the date of decease\n14. **state** isolated / released / deceased"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_patient.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_patient.isna().sum()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preprocessing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_patient['birth_year'] = df_patient.birth_year.fillna(0.0).astype(int)\ndf_patient['birth_year'] = df_patient['birth_year'].map(lambda val: val if val > 0 else np.nan)\ndf_patient.confirmed_date = pd.to_datetime(df_patient.confirmed_date)\ndaily_count = df_patient.groupby(df_patient.confirmed_date).patient_id.count()\naccumulated_count = daily_count.cumsum()\ndf_patient['age'] = 2020 - df_patient['birth_year'] \nimport math\ndef group_age(age):\n    if age >= 0: # not NaN\n        if age % 10 != 0:\n            lower = int(math.floor(age / 10.0)) * 10\n            upper = int(math.ceil(age / 10.0)) * 10 - 1\n            return f\"{lower}-{upper}\"\n        else:\n            lower = int(age)\n            upper = int(age + 9) \n            return f\"{lower}-{upper}\"\n    return \"Unknown\"\n\n\ndf_patient[\"age_range\"] = df_patient[\"age\"].apply(group_age)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patient=df_patient","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_cols = [\"confirmed_date\", \"released_date\", \"deceased_date\"]\nfor col in date_cols:\n    patient[col] = pd.to_datetime(patient[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patient[\"time_to_release_since_confirmed\"] = patient[\"released_date\"] - patient[\"confirmed_date\"]\npatient[\"time_to_death_since_confirmed\"] = patient[\"deceased_date\"] - patient[\"confirmed_date\"]\npatient[\"duration_since_confirmed\"] = patient[[\"time_to_release_since_confirmed\", \"time_to_death_since_confirmed\"]].min(axis=1)\npatient[\"duration_days\"] = patient[\"duration_since_confirmed\"].dt.days\nage_ranges = sorted(set([ar for ar in patient[\"age_range\"] if ar != \"Unknown\"]))\npatient[\"state_by_gender\"] = patient[\"state\"] + \"_\" + patient[\"sex\"]\nreleased = df_patient[df_patient.state == 'released']\nisolated_state = df_patient[df_patient.state == 'isolated']\ndead = df_patient[df_patient.state == 'deceased']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Confirmed Cases**"},{"metadata":{"trusted":true},"cell_type":"code","source":"accumulated_count.plot()\nplt.title('Accumulated Confirmed Count');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clus=df_route.loc[:,['id','latitude','longitude']]\nclus.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking for number of cluster**"},{"metadata":{"trusted":true},"cell_type":"code","source":"K_clusters = range(1,8)\nkmeans = [KMeans(n_clusters=i) for i in K_clusters]\nY_axis = df_route[['latitude']]\nX_axis = df_route[['longitude']]\nscore = [kmeans[i].fit(Y_axis).score(Y_axis) for i in range(len(kmeans))]\nplt.plot(K_clusters, score)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Score')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As in this graph, after 4 score go to constant value, so we will go with 4 clusters"},{"metadata":{},"cell_type":"markdown","source":"**K-Mean Clusterning**"},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters = 4, init ='k-means++')\nkmeans.fit(clus[clus.columns[1:3]])\nclus['cluster_label'] = kmeans.fit_predict(clus[clus.columns[1:3]])\ncenters = kmeans.cluster_centers_\nlabels = kmeans.predict(clus[clus.columns[1:3]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Graphical representation of clusters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"clus.plot.scatter(x = 'latitude', y = 'longitude', c=labels, s=50, cmap='viridis')\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=100, alpha=0.5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = daily_count.resample('D').first().fillna(0).cumsum()\ndata = data[20:]\nx = np.arange(len(data)).reshape(-1, 1)\ny = data.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Regression Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\nmodel = MLPRegressor(hidden_layer_sizes=[32, 32, 10], max_iter=50000, alpha=0.0005, random_state=26)\n_=model.fit(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = np.arange(len(data)+7).reshape(-1, 1)\npred = model.predict(test)\nprediction = pred.round().astype(int)\nweek = [data.index[0] + timedelta(days=i) for i in range(len(prediction))]\ndt_idx = pd.DatetimeIndex(week)\npredicted_count = pd.Series(prediction, dt_idx)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Graphical representatoin of current confirmed and predicted confirmed**"},{"metadata":{"trusted":true},"cell_type":"code","source":"accumulated_count.plot()\npredicted_count.plot()\nplt.title('Prediction of Accumulated Confirmed Count')\nplt.legend(['current confirmd count', 'predicted confirmed count'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prophet**"},{"metadata":{},"cell_type":"markdown","source":"**Making data ready for Prophet**"},{"metadata":{"trusted":true},"cell_type":"code","source":"prophet= pd.DataFrame(data)\nprophet\npr_data = prophet.reset_index()\npr_data.columns = ['ds','y']\npr_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model and prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"m=Prophet()\nm.fit(pr_data)\nfuture=m.make_future_dataframe(periods=365)\nforecast=m.predict(future)\nforecast","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Graphical Representation of Prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plot_plotly(m, forecast)\npy.iplot(fig) \n\nfig = m.plot(forecast,xlabel='Date',ylabel='Confirmed Count')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure=m.plot_components(forecast)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Autoregressive integrated moving average(Arima)**"},{"metadata":{},"cell_type":"markdown","source":"**Making data ready for Arima**"},{"metadata":{"trusted":true},"cell_type":"code","source":"confirm_cs = prophet.cumsum()\narima_data = confirm_cs.reset_index()\narima_data.columns = ['confirmed_date','count']\narima_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Model and prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ARIMA(arima_data['count'].values, order=(1, 2, 1))\nfit_model = model.fit(trend='c', full_output=True, disp=True)\nfit_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Graphical Representation for Prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_model.plot_predict()\nplt.title('Forecast vs Actual')\npd.DataFrame(fit_model.resid).plot()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Forcast for next 6 days"},{"metadata":{"trusted":true},"cell_type":"code","source":"forcast = fit_model.forecast(steps=6)\npred_y = forcast[0].tolist()\npd.DataFrame(pred_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**LSTM**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.DataFrame(data)\ndataset.columns = ['Confirmed']\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = np.array(dataset).reshape(-1, 1)\ntrain_data = dataset[:len(dataset)-5]\ntest_data = dataset[len(dataset)-5:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nscaler.fit(train_data)\nscaled_train_data = scaler.transform(train_data)\nscaled_test_data = scaler.transform(test_data)\nn_input =5\nn_features =1\n                             \ngenerator = TimeseriesGenerator(scaled_train_data,scaled_train_data, length=n_input, batch_size=1)\n\nlstm_model = Sequential()\nlstm_model.add(LSTM(units = 50, return_sequences = True, input_shape = (n_input, n_features)))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50, return_sequences = True))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(Dense(units = 1))\nlstm_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\nlstm_model.fit(generator, epochs = 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_model.history.history.keys()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses_lstm = lstm_model.history.history['loss']\nplt.figure(figsize = (30,4))\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.xticks(np.arange(0,100,1))\nplt.plot(range(len(losses_lstm)), losses_lstm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_predictions_scaled = []\n\nbatch = scaled_train_data[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test_data)):   \n    lstm_pred = lstm_model.predict(current_batch)[0]\n    lstm_predictions_scaled.append(lstm_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = pd.DataFrame(scaler.inverse_transform(lstm_predictions_scaled))\nprediction.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}